{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import cv2\n",
        "from torchvision.models.optical_flow import raft_small\n",
        "\n",
        "# Load video and save compressed data\n",
        "def load_video(file_path):\n",
        "    cap = cv2.VideoCapture(file_path)\n",
        "    frames = []\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        # Convert to RGB format\n",
        "        frames.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "    cap.release()\n",
        "    return frames\n",
        "\n",
        "# Save the reconstructed frames to a video\n",
        "def save_video(file_path, frames, fps=30):\n",
        "    height, width, _ = frames[0].shape\n",
        "    out = cv2.VideoWriter(file_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
        "    for frame in frames:\n",
        "        # Convert back to BGR format\n",
        "        out.write(cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n",
        "    out.release()\n",
        "\n",
        "# Simple example functions for key frame encoding/decoding\n",
        "def encode_key_frame(frame):\n",
        "    # Placeholder: Compress key frame (you can replace with actual model)\n",
        "    return frame\n",
        "\n",
        "def decode_key_frame(compressed_frame):\n",
        "    # Placeholder: Decompress key frame (you can replace with actual model)\n",
        "    return compressed_frame\n",
        "\n",
        "# Placeholder for motion estimation\n",
        "def estimate_flow(frame1, frame2):\n",
        "    model = raft_small(weights=\"Raft_Small_Weights.DEFAULT\").eval()  # Using weights\n",
        "    transform = nn.functional.interpolate\n",
        "    frame1_tensor = torch.from_numpy(frame1).float().permute(2, 0, 1).unsqueeze(0) / 255.0\n",
        "    frame2_tensor = torch.from_numpy(frame2).float().permute(2, 0, 1).unsqueeze(0) / 255.0\n",
        "    # Reshape to match RAFT input requirements\n",
        "    frame1_tensor = transform(frame1_tensor, size=(256, 256), mode='bilinear')\n",
        "    frame2_tensor = transform(frame2_tensor, size=(256, 256), mode='bilinear')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        flow_forward = model(frame1_tensor, frame2_tensor)[0]  # Flow from frame1 to frame2\n",
        "        flow_backward = model(frame2_tensor, frame1_tensor)[0]  # Flow from frame2 to frame1\n",
        "\n",
        "    return flow_forward, flow_backward  # Return both flows\n",
        "\n",
        "\n",
        "# Simple blending compensation\n",
        "def bi_directional_compensation(frame1, frame2, forward_flow, backward_flow):\n",
        "    # Placeholder: Combine frame1 and frame2 using motion flows\n",
        "    return (frame1 // 2 + frame2 // 2)\n",
        "\n",
        "# Simple residual encoding/decoding\n",
        "def encode_residual(residual):\n",
        "    # Placeholder: Encode residual\n",
        "    return residual\n",
        "\n",
        "def decode_residual(encoded_residual):\n",
        "    # Placeholder: Decode residual\n",
        "    return encoded_residual\n",
        "\n",
        "# Encode a video using the LHBDC-inspired method\n",
        "def encode_video(frames, gop_size=8):\n",
        "    compressed_frames = []\n",
        "    num_frames = len(frames)\n",
        "\n",
        "    for i in range(0, num_frames, gop_size):\n",
        "        key_frame = frames[i]\n",
        "        # Encode key frame\n",
        "        compressed_key_frame = encode_key_frame(key_frame)\n",
        "        compressed_frames.append(compressed_key_frame)\n",
        "\n",
        "        # Determine the last frame in the current GOP safely\n",
        "        end_frame_index = min(i + gop_size - 1, num_frames - 1)\n",
        "\n",
        "        # Process bi-directional frames within the GOP\n",
        "        for j in range(1, gop_size):\n",
        "            if i + j >= num_frames:\n",
        "                break\n",
        "            frame = frames[i + j]\n",
        "\n",
        "            # Use the last valid frame for flow estimation\n",
        "            forward_flow, backward_flow = estimate_flow(frames[i], frames[end_frame_index])\n",
        "\n",
        "            # Perform bi-directional compensation\n",
        "            compensated_frame = bi_directional_compensation(frames[i], frames[end_frame_index], forward_flow, backward_flow)\n",
        "            residual = frame - compensated_frame\n",
        "            encoded_residual = encode_residual(residual)\n",
        "            compressed_frames.append((forward_flow, backward_flow, encoded_residual))\n",
        "\n",
        "    return compressed_frames\n",
        "\n",
        "\n",
        "# Decode a video using the LHBDC-inspired method\n",
        "def decode_video(compressed_frames, gop_size=8):\n",
        "    reconstructed_frames = []\n",
        "    num_compressed_frames = len(compressed_frames)\n",
        "\n",
        "    for i in range(0, num_compressed_frames, gop_size):\n",
        "        key_frame = decode_key_frame(compressed_frames[i])\n",
        "        reconstructed_frames.append(key_frame)\n",
        "\n",
        "        # Determine the last frame in the current GOP safely\n",
        "        end_frame_index = min(i + gop_size - 1, num_compressed_frames - 1)\n",
        "\n",
        "        # Decode bi-directional frames\n",
        "        for j in range(1, gop_size):\n",
        "            if i + j >= num_compressed_frames:\n",
        "                break\n",
        "            forward_flow, backward_flow, encoded_residual = compressed_frames[i + j]\n",
        "\n",
        "            # Ensure the end reference frame is within bounds\n",
        "            if len(reconstructed_frames) <= end_frame_index:\n",
        "                end_reference_index = len(reconstructed_frames) - 1\n",
        "            else:\n",
        "                end_reference_index = end_frame_index\n",
        "\n",
        "            # Compensate using the closest available reconstructed frames\n",
        "            compensated_frame = bi_directional_compensation(reconstructed_frames[i], reconstructed_frames[end_reference_index], forward_flow, backward_flow)\n",
        "            residual = decode_residual(encoded_residual)\n",
        "            frame = compensated_frame + residual\n",
        "            reconstructed_frames.append(frame)\n",
        "\n",
        "    return reconstructed_frames\n",
        "\n",
        "\n",
        "# Main function to load video, compress, and decompress\n",
        "import pickle\n",
        "\n",
        "def main(input_video_path, output_compressed_path, output_decompressed_path):\n",
        "    frames = load_video(input_video_path)\n",
        "\n",
        "    # Encode video\n",
        "    print(\"Encoding video...\")\n",
        "    compressed_frames = encode_video(frames)\n",
        "    print(\"Encoding completed...\")\n",
        "\n",
        "    # Decode video\n",
        "    print(\"Decoding video...\")\n",
        "    reconstructed_frames = decode_video(compressed_frames)\n",
        "    print(\"Decoding completed...\")\n",
        "\n",
        "    # Save compressed data using pickle\n",
        "    with open(output_compressed_path, 'wb') as f:\n",
        "        pickle.dump(compressed_frames, f)  # Save the compressed frames\n",
        "\n",
        "    # Save reconstructed video\n",
        "    save_video(output_decompressed_path, reconstructed_frames)\n",
        "\n",
        "# Run the example\n",
        "input_video_path = \"/content/sample_data/video.mp4\"\n",
        "output_compressed_path = \"compressed_video.pkl\"  # Change the extension to .pkl\n",
        "output_decompressed_path = \"decompressed_video.mp4\"\n",
        "main(input_video_path, output_compressed_path, output_decompressed_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GllqAG_G4tg2",
        "outputId": "13e65d23-0229-4427-a966-8cd441c1184e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding video...\n",
            "Encoding completed...\n",
            "Decoding video...\n",
            "Decoding completed...\n"
          ]
        }
      ]
    }
  ]
}